{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie danych\n",
    "\n",
    "Naszym pierwszym zadaniem jest przygotowanie wsadu dla modeli uczenia maszynowego. Zrobimy to przy wykorzystaniu `numpy`, `pandas` i `rasterio`, generując szybko ramkę danych z kolumnami `NDVI`, `NDWI`, `SCI` i kolumną `y`, która reprezentować będzie dane binarne: **to, czy dany piksel jest terenem zabudowanym, czy nie jest**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_imaging' from 'PIL' (/usr/lib/python3/dist-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mneural_network\u001b[39;00m \u001b[39mimport\u001b[39;00m MLPClassifier\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbands\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload\u001b[39;00m \u001b[39mimport\u001b[39;00m LoadBandsFromTif\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import seaborn objects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrcmod\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpalettes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/rcmod.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Control plot style and scaling using the matplotlib rcParams interface.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcycler\u001b[39;00m \u001b[39mimport\u001b[39;00m cycler\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m palettes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/__init__.py:113\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpackaging\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m parse \u001b[39mas\u001b[39;00m parse_version\n\u001b[1;32m    111\u001b[0m \u001b[39m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[1;32m    114\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m sanitize_sequence\n\u001b[1;32m    115\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m \u001b[39mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/rcsetup.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _api, cbook\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcbook\u001b[39;00m \u001b[39mimport\u001b[39;00m ls_mapper\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m Colormap, is_color_like\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_fontconfig_pattern\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_enums\u001b[39;00m \u001b[39mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/colors.py:51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumbers\u001b[39;00m \u001b[39mimport\u001b[39;00m Number\n\u001b[1;32m     50\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPngImagePlugin\u001b[39;00m \u001b[39mimport\u001b[39;00m PngInfo\n\u001b[1;32m     54\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:69\u001b[0m\n\u001b[1;32m     60\u001b[0m MAX_IMAGE_PIXELS \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[39m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _imaging \u001b[39mas\u001b[39;00m core\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m __version__ \u001b[39m!=\u001b[39m \u001b[39mgetattr\u001b[39m(core, \u001b[39m\"\u001b[39m\u001b[39mPILLOW_VERSION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     72\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     73\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCore version: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPillow version: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mgetattr\u001b[39m(core, \u001b[39m\"\u001b[39m\u001b[39mPILLOW_VERSION\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), __version__)\n\u001b[1;32m     76\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_imaging' from 'PIL' (/usr/lib/python3/dist-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bands.load import LoadBandsFromTif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINARY_DATA = './results/clc_results/binarized_clc.tif'\n",
    "NDVI_DATA = './results/ndvi.tif'\n",
    "NDWI_DATA = './results/ndwi.tif'\n",
    "SCI_DATA = './results/sci.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz ułożymy wartości do ramki danych, najpierw wczytamy wszystkie dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_band = LoadBandsFromTif(BINARY_DATA).get_band()\n",
    "ndv_band = LoadBandsFromTif(NDVI_DATA).get_band()\n",
    "ndw_band = LoadBandsFromTif(NDWI_DATA).get_band()\n",
    "sci_band = LoadBandsFromTif(SCI_DATA).get_band()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz utworzymy ramkę danych... najpierw wszystkie wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4445532, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.empty(shape=(len(bin_band.flatten()), 4))\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:, 0] = bin_band.flatten()\n",
    "arr[:, 1] = ndv_band.flatten()\n",
    "arr[:, 2] = ndw_band.flatten()\n",
    "arr[:, 3] = sci_band.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndwi</th>\n",
       "      <th>sci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861824</td>\n",
       "      <td>-0.827907</td>\n",
       "      <td>0.827907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857498</td>\n",
       "      <td>-0.818329</td>\n",
       "      <td>0.818329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857490</td>\n",
       "      <td>-0.826433</td>\n",
       "      <td>0.826433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.868816</td>\n",
       "      <td>-0.825994</td>\n",
       "      <td>0.825994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865950</td>\n",
       "      <td>-0.835684</td>\n",
       "      <td>0.835684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y      ndvi      ndwi       sci\n",
       "0  0.0  0.861824 -0.827907  0.827907\n",
       "1  0.0  0.857498 -0.818329  0.818329\n",
       "2  0.0  0.857490 -0.826433  0.826433\n",
       "3  0.0  0.868816 -0.825994  0.825994\n",
       "4  0.0  0.865950 -0.835684  0.835684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['y', 'ndvi', 'ndwi', 'sci']\n",
    "df = pd.DataFrame(data=arr, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytamy podstawowe informacje o danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4445532 entries, 0 to 4445531\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   y       float64\n",
      " 1   ndvi    float64\n",
      " 2   ndwi    float64\n",
      " 3   sci     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 135.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>4445532.0</td>\n",
       "      <td>0.586137</td>\n",
       "      <td>0.492525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi</th>\n",
       "      <td>4445532.0</td>\n",
       "      <td>0.519922</td>\n",
       "      <td>0.254621</td>\n",
       "      <td>-0.740552</td>\n",
       "      <td>0.307663</td>\n",
       "      <td>0.571663</td>\n",
       "      <td>0.751201</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndwi</th>\n",
       "      <td>4445532.0</td>\n",
       "      <td>-0.557063</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.727110</td>\n",
       "      <td>-0.611056</td>\n",
       "      <td>-0.411924</td>\n",
       "      <td>0.715823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci</th>\n",
       "      <td>4445532.0</td>\n",
       "      <td>0.557063</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>-0.715823</td>\n",
       "      <td>0.411924</td>\n",
       "      <td>0.611056</td>\n",
       "      <td>0.727110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std       min       25%       50%       75%  \\\n",
       "y     4445532.0  0.586137  0.492525  0.000000  0.000000  1.000000  1.000000   \n",
       "ndvi  4445532.0  0.519922  0.254621 -0.740552  0.307663  0.571663  0.751201   \n",
       "ndwi  4445532.0 -0.557063  0.207317 -1.000000 -0.727110 -0.611056 -0.411924   \n",
       "sci   4445532.0  0.557063  0.207317 -0.715823  0.411924  0.611056  0.727110   \n",
       "\n",
       "           max  \n",
       "y     1.000000  \n",
       "ndvi  1.000000  \n",
       "ndwi  0.715823  \n",
       "sci   1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane wyglądają na prawidłowe.\n",
    "Zapiszemy dataframe do pliku csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./results/prepared_frame.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ powyższy plik csv jest bardzo duży nie dodałam go do repozytorium, dostępny jest pod linkiem: https://drive.google.com/file/d/19j4ZU3wLrPNlQbX7DQIPrINN6MxAnUC9/view?usp=share_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformacja danych wejściowych i podział na zbiór treningowy i testowy.\n",
    "\n",
    "W tym kroku przygotowujemy dane jako wsad do modeli uczenia maszynowego. Jako że wskaźniki są już w przedziale -1 do 1, możemy tylko podzielić dane na zbiór treningowy i testowy. Wykorzystamy do tego możliwości, jakie daje pakiet `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.drop('y', axis=1),\n",
    "    df['y'],\n",
    "    random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count      mean       std       min       25%       50%       75%  \\\n",
      "ndvi  3334149.0  0.519918  0.254616 -0.740552  0.307630  0.571672  0.751152   \n",
      "ndwi  3334149.0 -0.557048  0.207348 -1.000000 -0.727063 -0.611058 -0.411840   \n",
      "sci   3334149.0  0.557048  0.207348 -0.715823  0.411840  0.611058  0.727063   \n",
      "\n",
      "           max  \n",
      "ndvi  1.000000  \n",
      "ndwi  0.715823  \n",
      "sci   1.000000  \n",
      "------------------------------------------------------------------------------\n",
      "          count      mean       std       min       25%       50%       75%  \\\n",
      "ndvi  1111383.0  0.519933  0.254637 -0.667292  0.307802  0.571625  0.751345   \n",
      "ndwi  1111383.0 -0.557110  0.207225 -1.000000 -0.727244 -0.611053 -0.412178   \n",
      "sci   1111383.0  0.557110  0.207225 -0.626313  0.412178  0.611053  0.727244   \n",
      "\n",
      "           max  \n",
      "ndvi  1.000000  \n",
      "ndwi  0.626313  \n",
      "sci   1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(x_train.describe().T)\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(x_test.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór y trening liczy 3334149 elementów.\n",
      "Zbiór y testowy liczy 1111383 elementów.\n"
     ]
    }
   ],
   "source": [
    "print(\"Zbiór y trening liczy\", y_train.count(), \"elementów.\")\n",
    "print(\"Zbiór y testowy liczy\", y_test.count(), \"elementów.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening różnych klasyfikatorów dostępnych w pakiecie scikit-learn.\n",
    "\n",
    "Najpierw przeprowadzimy trening różnych klasyfikatorów dostępnych w pakiecie scikit-learn. Spośród nich wybierzemy:\n",
    "\n",
    "> I. Drzewa decyzyjne,\n",
    "\n",
    "> II. Lasy losowe,\n",
    "\n",
    "> III. Naiwny Bayesowski klasyfikator,\n",
    "\n",
    "> IV. Ada Boost,\n",
    "\n",
    "> V. prostą sieć neuronową.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drzewa decyzyjne\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion='gini', \n",
    "                                                  max_depth=10, \n",
    "                                                  min_samples_split=3, \n",
    "                                                  random_state=14)\n",
    "\n",
    "decision_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predykcje\n",
    "\n",
    "decision_tree_predictions = decision_tree_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasy losowe\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=20,\n",
    "                                                  max_depth=10,\n",
    "                                                  n_jobs=-1)\n",
    "random_forest_classifier.fit(x_train, y_train)\n",
    "predictions_random_forest = random_forest_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(x_train, y_train)\n",
    "predictions_bayes = nb_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada Boost\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=20)\n",
    "adaboost_classifier.fit(x_train, y_train)\n",
    "predictions_ada = adaboost_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sieć neuronowa\n",
    "\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(16, 16, 8, 2),\n",
    "                              max_iter=30,\n",
    "                              n_iter_no_change=5)\n",
    "nn_classifier.fit(x_train, y_train)\n",
    "predictions_nn = nn_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening klasyfikatora opartego na uczeniu głębokim przy wykorzystaniu pakietu Keras.\n",
    "\n",
    "W tym momencie moglibyśmy już przerwać nasz trening i przejść do analizy wyników. Jednak dla porównania zastosujemy również sieć neuronową opartą na pakiecie `keras` i module `Tensorflow`. Taką sieć buduje się nieco inaczej niż tę z pakietu `scikit-learn`.\n",
    "\n",
    "Do trenowania sieci neuronowej opartej na uczeniu głębokim potrzebować będziemy również zbioru walidacyjnego, dlatego podzielimy jeszcze nasz zbiór treningowy na dwie części: 1/5 zbioru zostanie odłożona do walidacji trenowanego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel.add(Dense(16, activation='relu'))\n",
    "kmodel.add(Dense(16, activation='relu'))\n",
    "kmodel.add(Dense(8, activation='relu'))\n",
    "kmodel.add(Dense(2, activation='relu'))\n",
    "kmodel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel.compile(loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(0.2 * len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:val_size]\n",
    "x_train_kmodel = x_train[val_size:]\n",
    "\n",
    "y_val = y_train[:val_size]\n",
    "y_train_kmodel = y_train[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = kmodel.fit(x_train_kmodel, y_train_kmodel,\n",
    "                     epochs=10, batch_size=2048,\n",
    "                     validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wytrenowaniu modelu sprawdźmy stratę trenowania i walidacji oraz dokładność trenowania i walidacji, by przekonać się, czy nie wystąpiło zjawisko przewymiarowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Strata trenowania')\n",
    "plt.plot(epochs, val_loss, 'b', label='Strata walidacji')\n",
    "\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Strata')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'ro', label='Dokładność trenowania')\n",
    "plt.plot(epochs, val_acc, 'r', label='Dokładność walidacji')\n",
    "\n",
    "plt.xlabel('Epoki')\n",
    "plt.ylabel('Dokładność')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym wypadku dane nie są przewymiarowe, więc możemy dokonać predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_keras = kmodel.predict(x_test, batch_size=2048)\n",
    "predicted_keras[predicted_keras > 0.5] = 1\n",
    "predicted_keras[predicted_keras <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zestawienie wyników poszczególnych modeli.\n",
    "\n",
    "Jak sprawują się poszczególne modele? Możemy to zbadać wykorzystując w tym celu macierze błędów i inne metryki opracowane dla klasyfikatorów. Funkcje, które je obliczają, dostępne są w pakiecie `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_output(predictions, y_t):\n",
    "    \n",
    "    output = accuracy_score(y_t, predictions)\n",
    "    confusion = confusion_matrix(y_t, predictions, normalize='true')\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    sns.heatmap(confusion, annot=True, cmap='winter')\n",
    "\n",
    "    print('Accuracy score is:', output)\n",
    "    p_r_f1 = precision_recall_fscore_support(y_t, predictions, average='macro')\n",
    "    print('Precision: {}, Recall: {}, F1 score: {}'.format(p_r_f1[0], p_r_f1[1], p_r_f1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function confusion_matrix at 0x7fa9b7b6d2d0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Drzewa decyzyjne\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m show_predicted_output(decision_tree_predictions, y_test)\n",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m, in \u001b[0;36mshow_predicted_output\u001b[0;34m(predictions, y_t)\u001b[0m\n\u001b[1;32m      4\u001b[0m confusion \u001b[39m=\u001b[39m confusion_matrix(y_t, predictions, normalize\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(confusion_matrix)\n\u001b[0;32m----> 7\u001b[0m sns\u001b[39m.\u001b[39mheatmap(confusion, annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwinter\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy score is:\u001b[39m\u001b[39m'\u001b[39m, output)\n\u001b[1;32m     10\u001b[0m p_r_f1 \u001b[39m=\u001b[39m precision_recall_fscore_support(y_t, predictions, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "# Drzewa decyzyjne\n",
    "\n",
    "show_predicted_output(decision_tree_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasy Losowe\n",
    "\n",
    "show_predicted_output(predictions_random_forest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes\n",
    "\n",
    "show_predicted_output(predictions_bayes, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA\n",
    "\n",
    "show_predicted_output(predictions_ada, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sieci Neuronowe = scikit\n",
    "\n",
    "show_predicted_output(predictions_nn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "\n",
    "show_predicted_output(predicted_keras, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
